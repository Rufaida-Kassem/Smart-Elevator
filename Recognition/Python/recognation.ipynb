{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports you will need in the whole lab\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import numpy as np \n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp_hist(grayscale_img):\n",
    "    # initialize the 2D matrix by zeros\n",
    "    hist = np.zeros(256)\n",
    "    # begin from 1 and end at size - 1 to ignore the borders\n",
    "    for i in range (1, grayscale_img.shape[0] - 1):\n",
    "        for j in range (1, grayscale_img.shape[1] - 1):\n",
    "            b = 0b00000000\n",
    "            if(grayscale_img[i - 1][j- 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b10000000\n",
    "            if(grayscale_img[i - 1][j] > grayscale_img[i][j]):\n",
    "                b = b | 0b01000000\n",
    "            if(grayscale_img[i - 1][j+ 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b00100000\n",
    "            if(grayscale_img[i][j + 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b00010000\n",
    "            if(grayscale_img[i + 1][j + 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b00001000\n",
    "            if(grayscale_img[i + 1][j] > grayscale_img[i][j]):\n",
    "                b = b | 0b00000100\n",
    "            if(grayscale_img[i + 1][j- 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b00000010\n",
    "            if(grayscale_img[i][j- 1] > grayscale_img[i][j]):\n",
    "                b = b | 0b00000001\n",
    "            hist[b] = hist[b] + 1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbph_input(images):\n",
    "    #images_lbp=localBinaryPattern(images)\n",
    "    print(images.shape)\n",
    "    hist = []  \n",
    "    face_resize = cv2.resize(images, (256, 256))  \n",
    "    (s2,s3) = face_resize.shape        \n",
    "    img_lbp = np.zeros((s2,s3,1), np.uint8)  \n",
    "    io.imshow(face_resize)\n",
    "    io.show()\n",
    "    hist_lbp = get_lbp_hist(face_resize)\n",
    "    hist.append(hist_lbp)\n",
    "                #print(hist_lbp)  \n",
    "         # images_lbp=localBinaryPattern(images)  \n",
    "         #   \n",
    "    return hist \n",
    "    \n",
    "\n",
    "#LBPH.predict(Face) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbph(images):\n",
    "    #images_lbp=localBinaryPattern(images)\n",
    "    #print(images.shape)\n",
    "    s1 = images.shape[0]\n",
    "    hist = []  \n",
    "    for k in range(s1):\n",
    "        for face in images[k]:\n",
    "            face_resize = cv2.resize(face, (256, 256))  \n",
    "            (s2,s3) = face_resize.shape\n",
    "            img_lbp = np.zeros((s2,s3,1), np.uint8)   \n",
    "            hist_lbp = get_lbp_hist(face_resize)  \n",
    "            hist.append(hist_lbp)\n",
    "                #print(hist_lbp)  \n",
    "         # images_lbp=localBinaryPattern(images)  \n",
    "         #   \n",
    "    return hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compares from training and coming image\n",
    "def predict_lbph(input_image,recognizer,labels):\n",
    "    d1=recognizer.shape[0]\n",
    "    input_hist = train_lbph_input(input_image)\n",
    "    distance = 0\n",
    "    thresh = 2000000\n",
    "    index = 0\n",
    "    eps = 1e-10\n",
    "    for i in range(d1):\n",
    "        distance = 0.005 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
    "        for (a, b) in zip(recognizer[i,:], input_hist)])\n",
    "        if distance<thresh:\n",
    "            index=i\n",
    "            thresh=distance\n",
    "    return (labels[index],thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make preprocessing then uses this\n",
    "def extract_faces_label(gray,save):\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades +  \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=4,\n",
    "        minSize=(60, 60)\n",
    "    )\n",
    "    face_images=[]\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(gray, (x, y-15), (x+w, y+h), (0, 255, 0), 2)\n",
    "        #cv2.putText(gray, 'mhmd' , (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "        roi_color = gray[y-15:y + h, x:x + w]\n",
    "        \n",
    "        face_images.append(roi_color)\n",
    "        if(save == 1):\n",
    "            io.imsave('../TrainedResults/' + str(w) + str(h) + '_faces.jpg', roi_color)\n",
    "    if(save == 1):\n",
    "        io.imsave('faces_detected.jpg'+names.get_full_name(), image)\n",
    "\n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_lbp_label(train):\n",
    "    (images, labels, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk('../TrainingImages'):\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join('../TrainingImages', subdir)\n",
    "            num=0\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                lable = subdir\n",
    "                images.append(cv2.imread(path, 0))\n",
    "                labels.append(lable)\n",
    "                num+=1\n",
    "\n",
    "            id += 1\n",
    "    (im_width, im_height) = (68, 68)\n",
    "\n",
    "    # Create a np array from the two lists above\n",
    "    (images_arr, labels_arr) = [np.array(lis) for lis in [images, labels]]\n",
    "    if(train == 1):\n",
    "        s1 = images_arr.shape[0]\n",
    "        total_faces=[]\n",
    "        for i in range(s1):\n",
    "            faces = extract_faces_label(images_arr[i],0)   \n",
    "            total_faces.append(faces)\n",
    "\n",
    "        (faces_arr, labels_arr) = [np.array(lis) for lis in [total_faces, labels]]\n",
    "        trained_face_recognizer=train_lbph(faces_arr) \n",
    "        print('done')\n",
    "        np.save('trained.npy',trained_face_recognizer)\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=training_lbp_label(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(imgfile):\n",
    "    \n",
    "    # save np.load\n",
    "    np_load_old = np.load\n",
    "    # modify the default parameters of np.load\n",
    "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "    trained_face_recognizer=np.load('trained.npy')\n",
    "    # restore np.load for future normal usage\n",
    "    np.load = np_load_old\n",
    "    myimage=io.imread('../TestImages/'+imgfile)\n",
    "    gray = cv2.cvtColor(myimage, cv2.COLOR_BGR2GRAY)\n",
    "    faces=extract_faces_label(gray,0)\n",
    "\n",
    "    for face in faces:\n",
    "        prediction=predict_lbph(face,trained_face_recognizer,labels)\n",
    "        if (prediction[1])<3000:\n",
    "            print(prediction[0])\n",
    "            cv2.putText(myimage,'recognized - %.0f' % (prediction[1]),(10, 10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "        else:\n",
    "            cv2.putText(myimage,'not recognized',(10, 10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('salaah_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70d459914d9a86456d6cb0e34fc8190790cc0df25ff27e38f763783165fe5050"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
